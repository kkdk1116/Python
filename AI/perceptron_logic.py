# -*- coding: utf-8 -*-
"""Perceptron_Logic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1txC9YBzhDp2L7zckgwkgNVQCf9psHlNO
"""

import numpy as np


# Delta Rule
# w(i+1) = w(i) + lrate * Err * input
# Delta 
import numpy as np
def sigmoid(x) :
  return (1.0/(1.0 + np.exp(-x)))

def act_tlu(out) :
  if(out > 0.0) :
      return 1.0
  return(0.0)

x = np.array([ [1.0, 0.0, 0.0], [1.0, 0.0, 1.0], [1.0, 1.0, 0.0], [1.0, 1.0, 1.0] ])


#t = np.array([[1.0, 0.0], [0.0, 1.0]]) A, B

t = np.array([0.0, 0.0, 0.0, 1.0]) # p0~p3 타겟     -출력-

lrate = 0.8

#w = np.zeros((2,9))

#for i in range(2) :
  #for j in range(9) :
    #w[i][j]= np.random.rand((2,9))

w = np.zeros(3)

w[0] = 0.5
w[1] = 0.2
w[2] = 0.7

for epoch in range (200):
  print("epoch", epoch)
  for i in range(4):
    out = w[0]*x[i][0] + w[1]*x[i][1] + w[2]*x[i][2]
    #b = act_tlu(out)
    b = sigmoid(out)
    print(t[i], b, out)  # 디버깅
    #print(w)
    for j in range(3):
      #w[j] = w[j] + lrate * (t[i]-b) *x[i][j] # (t[i]-b)=에러 i는 고정, j가 변함
      w[j] = w[j] + lrate * (t[i]-b) *b *(1-b) *x[i][j] #sigmid