# -*- coding: utf-8 -*-
"""torchMNIST_modelNN_GPU.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XOxkGeFC0W8EibHVppuebnEVO2FDAdjg
"""

# -*- coding: utf-8 -*-
"""torchMNIST_modelNN_GPU.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13VdigVUf7GItzyFu1rH6vNBn-fSUj54e
"""

# -*- coding: utf-8 -*-
"""3층 mlp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uF2rfs4FvBFGummqv4yHbSx9bYQMwPYI
"""

import torch
from torch import tensor
from torchvision import datasets
from torchvision.transforms import ToTensor
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim


#학습 할 때는 셔플이 좋지만 테스트 할 때는 셔플이 좋지 않을 수 있다.(안 하는게 좋다)

training_data = datasets.MNIST("data", train=True, download=True, transform=ToTensor())
test_data = datasets.MNIST("data", train=False, download=True, transform=ToTensor())

trainLoader = torch.utils.data.DataLoader(training_data, batch_size=64, shuffle=True, drop_last=False) # 64개씩 섞어서 가져옴
testLoader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True, drop_last=False) # 64개씩 섞어서 가져옴

yt = tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
             [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
             [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
             [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
             [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
             [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
             [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
             [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
             [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
             [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])
temp = len(trainLoader)
print(temp)

class network(nn.Module):  # 네트워크 모델 정의
# init와 forward는 무조건 있어야 한다.

    def __init__(self, in_f1, in_f2, in_f3, out_f):  # 구조(생성자)
        super(network, self).__init__() 
        self.fc1 = nn.Linear(in_f1, in_f2)  # in_features=784, out_features=300, bias=True
        self.fc2 = nn.Linear(in_f2, in_f3)  # in_features=300, out_features=100, bias=True
        self.fc3 = nn.Linear(in_f3, out_f)  # in_features=100, out_features=10,  bias=True
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):  # 액션
        x = x.view(-1, 28 * 28)  # 1차원 행렬로 변환
        x1 = self.sigmoid(self.fc1(x))  # 히든 1층의 출력
        x2 = self.sigmoid(self.fc2(x1))  # 히든 2층의 출력
        x3 = self.sigmoid(self.fc3(x2))  # 출력층의 출력
        return x3

# gpu에서 네트워크를 처리

if torch.cuda.is_available(): # GPU의 병렬처리언어
    device = torch.device("cuda:0")
    print("running on the GPU")
else:
    device = torch.device("cpu")
    print("running on the CPU")

model = network(784, 300, 100, 10)  # .to(device)  4개의 인자가 init로 들어감
model.to(device) # cpu에 있던 모델이 GPU 혹은 CPU 그 자리로 보내서 계산

Epochs = 3

#optimizer = optim.SGD(model.parameters(), lr=0.01)
optimizer = optim.Adam(params=model.parameters(), lr=0.01)
criterion = nn.MSELoss()
batch_count = len(trainLoader)


def train():
    for epoch in range(Epochs):
        loss_sum = 0
        for data, target in trainLoader:     # 64개씩 1000번 -> 약 6만번
            X, y = data.to(device), yt[target].to(device) # yt는 y로
            #model.zero_grad()
            optimizer.zero_grad()       # 초기화

            prediction = model(X)  # 1. forward      인스턴스의 인자는 액션이기 때문에 forward로 들어간다. prediction은 변수 이름 , 64개가 출력

            loss = criterion(prediction, y.to(torch.float32))  # 2_1 Loss           64개와 64개를 비교해서 loss값을 구함
            loss.backward()  # 2_2. backpropagation      # loss값을 백프로파게이션

            optimizer.step()  # 3. update weight       # 에러만큼 교정하고 업데이트

            loss_sum += loss.item()
        print("epoch :", epoch)
        print("loss = " + str(round(loss_sum / batch_count, 3)))
        #if epoch%5 == 0 :
           #test()

def test():
    correct = 0
    # 데이터로더에서 하나씩 꺼내 추론
    with torch.no_grad():
        for data, target in testLoader:    # test 데이터 1만개 들어있음
            data, target = data.to(device), target.to(device) # 1바퀴 돌때마다 64개 데이터 들어감
            outputs = model(data.view(-1, 784))  # prediction   64개의 데이터들의 결과가 나옴

            # 정확성 판정
            predicted = torch.max(outputs, dim=1)[1]  # 가장 큰 인덱스 위치를 리턴함  @ return value, index ,  제일 정확한 값, 64개가 하나로만 쭉 나옴 , 잘 모르겠으면 print찍어봐서 확인해보기
            correct += predicted.eq(target).sum()  # 정답과 일치한 경우 정답 카운트를 증가 ,   64개와 답 비교,     맞았다=1, 틀렸다=0 , 잘 모르겠으면 print찍어봐서 확인해보기
            #print("Target:", target, "Output:", predicted)

    data_num = len(test_data)  # 데이터 총 건수
    print('Accurancy : ({:.3f}%)\n'.format(correct / 100))

fc1 = nn.Linear(784, 20)
sigmoid = nn.Sigmoid()

print(fc1)
print(sigmoid)

for data, target in trainLoader:
            X, y = data.to(device), yt[target].to(device)
x = X.view(-1, 28 * 28)  # 1차원 행렬로 변환

x = sigmoid(fc1(x))  # 히든 1층의 출력
print(x)

train()

test()

train()

test()