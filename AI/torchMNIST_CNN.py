# -*- coding: utf-8 -*-
"""torchMNIST_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CO7eoby3SaMc9_xNoq-eiZX4kVpYFQsN
"""

import torch
from torch import tensor
from torchvision import datasets
from torchvision.transforms import ToTensor
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset # 가장 중요한 라이브러리
import matplotlib.pyplot as plt # 그래픽 라이브러리 중요함! 사용법 따로 공부해야하는 듯 시험에 나올수도 있음

device = 'cuda' if torch.cuda.is_available() else 'cpu'
#torch.manual_seed(777) # 랜덤넘버에 사용, 랜덤의 시작위치, 777부터 사용, 보통 777자리에 타이머를 사용함, 실습할때는 안 하는게 좋음, 현장에서 사용하자.
if device == 'cuda':
    torch.cuda.manual_seed_all(777)
print(device + " is using")

training_data = datasets.MNIST("data", train=True, download=True, transform=ToTensor()) # 6만개 존재, 점 데이터를 텐서형태로 변환해서 가져옴, 배열과 텐서는 다름 (차이점 주의)
test_data = datasets.MNIST("data", train=False, download=True, transform=ToTensor()) # 1만개 존재, 테스트이므로  train=False, 점 데이터를 텐서형태로 변환해서 가져옴, 배열과 텐서는 다름 (차이점 주의)

trainLoader = torch.utils.data.DataLoader(training_data, batch_size=100, shuffle=True, drop_last=False) # 6만자중에 100개씩 GPU에 던져줌, 100개를 섞어서 던짐(shuffle), 100개씩 자르고 남은 자투리를 버린다. 60050개이면 50개를 버림(drop_last=Flase)
testLoader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=True, drop_last=False) # 1만자중에 100개씩 GPU에 던져줌, 100개를 섞어서 던짐(shuffle), 100개씩 자르고 남은 자투리를 버린다. 10050개이면 50개를 버림(drop_last=Flase)


#init (네트워크생성) 와 forward (액션) 두 부분으로 나눔

class network(nn.Module):  # 네트워크 모델 정의
    def __init__(self):
        super(network, self).__init__()
        self.conv = nn.Sequential( # Sequential 묶인 부분 차례로 실행
            nn.Conv2d(1, 6, (3, 3), padding=1),   # in_channels = 1, out_channels = 6, kernel_size = 3       output = 28 * 28 * 6   Convoluton 단계, 1개의 그림, 6개의 필터(3x3), 패딩=1
            nn.ReLU(),                            # 값은 유지, 음수만 없애줌
            nn.MaxPool2d(2, 2),                   # max 풀링  kernel_size = 2, stride = 2                     output = 14 * 14 * 6   2x2, 스트라이브가 2 -> 사이즈가 2배 줄어듬
            nn.Conv2d(6, 16, (3, 3), padding=1),  # in_channels = 6, out_channels = 16, kernel_size = 3      output = 14 * 14 * 16  Convoluton 단계, 6개의 그림, 필터를 16개로 적용(3x3), 패딩=1, 인풋 6개 아웃풋 16개
            nn.ReLU(),                            # 값은 유지, 음수만 없애줌
            nn.MaxPool2d(2, 2)                    # max 풀링  kernel_size = 2, stride = 2                     output =  7 *  7 * 16
        )
        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
        # torch.nn.MaxPool2d( kernel_size , stride = None , padding = 0 , dilation = 1 , return_indices = False , ceil_mode = False )

        self.fully_connected = nn.Sequential(  # Sequential 묶인 부분 차례로 실행
            nn.Linear(16 * 7 * 7, 120),  # 1층 레이어 7x7 영상이 16개, 120개 노드를 뿌림 (H1DIM)
            nn.Linear(120, 84),          # 2층 레이어
            nn.Linear(84, 10)            # 3층 레이어
        )

    def forward(self, x):
        x = self.conv(x)
        x = x.view(-1, 16 * 7 * 7)  # 1차원 전환  (nn.flatten) ,16개를 1차원으로 쫙 펼침 (7x7을 16개로 쫙 펼침)
        x = self.fully_connected(x)
        return x


def train():
    for epoch in range(Epochs):
        loss_sum = 0
        for data, target in trainLoader:
            X, y = data.to(device), target.to(device)  # cross
            optimizer.zero_grad()
            prediction = model(X)  # 결과 출력
            loss = criterion(prediction, y)  # cross 로스 계산
            loss.backward()  # 로스 역전파
            optimizer.step()  # 실질적 웨이트 수정
            loss_sum += loss.item()
        print("epoch = %d   loss = %f" % (epoch + 1, round(loss_sum / batch_count, 3)))
        test()


def test():
    correct = 0
    with torch.no_grad():
        for data, target in testLoader:
            data, target = data.to(device), target.to(device)
            outputs = model(data)  # 출력 계산

            # 추론 계산
            _, predicted = torch.max(outputs, 1)  # 가장 큰 인덱스 위치를 리턴함  @ return value, index
            correct += predicted.eq(target).sum()  # 정답과 일치한 경우 정답 카운트를 증가

    data_num = len(test_data)  # 데이터 총 건수
    print("accuracy = {}/10000\n".format(correct))


model = network().to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

Epochs = 2
batch_count = len(trainLoader)

train()

#MNIST 10번째 값 띄워보기, import matplotlib.pyplot as plt 사용법 숙지해서 해보기

import numpy as np
import matplotlib.pyplot as plt

from tensorflow import keras
mnist = keras.datasets.mnist
(train_images, train_labels),(test_images, test_labels) = mnist.load_data()

mnist_idx = 9

plt.figure(figsize=(10, 10))
image = train_images[mnist_idx]
plt.imshow(image)
plt.show()